{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 3000\n",
    "\n",
    "\n",
    "def my_remove_highly_correlated(X,threshold):\n",
    "\n",
    "    X = X.select_dtypes(include=[np.number])  #.dropna()\n",
    "    \n",
    "    cols = X.columns\n",
    "\n",
    "    #run correlation matrix\n",
    "    df = X.corr()\n",
    "   \n",
    "    #put df into array\n",
    "    a = df.values\n",
    "    \n",
    "    #label top half with -99999 \n",
    "    #we want to ignore top half of matrix\n",
    "    iu1 = np.triu_indices(len(df))\n",
    "    a[iu1] = -99999\n",
    "    #put data back into dataframe\n",
    "    df = pd.DataFrame(a, columns=cols)\n",
    "    df['var'] = cols\n",
    "    \n",
    "    #unstack to get a list of var1, var2, correlation\n",
    "    df = pd.melt(df, id_vars=['var'])\n",
    "        \n",
    "    #remove those flagged with -99999\n",
    "    df = df[df.value != -99999].sort_values(by='var', ascending=True)\n",
    "  \n",
    "    #flag remove vs keep based on corr threshold\n",
    "    df_remove = df[df.value > threshold]\n",
    "    remove_list = df_remove['var'].unique()\n",
    " \n",
    "    print('{} out of {} vars removed due to corr greater than {}'.\n",
    "          format(df_remove.shape[0],X.shape[1],threshold))\n",
    "    \n",
    "    new_df = X.drop(columns=remove_list, axis=1)\n",
    "    \n",
    "    print(df_remove)\n",
    "    print('\\nShape before: ' + str(X.shape))\n",
    "    print('Shape after: ' + str(new_df.shape))\n",
    "    print('\\n')\n",
    "    return new_df\n",
    "\n",
    "def my_drop_na_columns(X,NANthreshold):\n",
    "\n",
    "    df = X\n",
    "    colcount = df.shape[1]\n",
    "    #Get count of NA in each column\n",
    "    series_cols = df.isnull().sum(axis = 0).sort_values(ascending=False)\n",
    "\n",
    "    #filter the list to include only those with counts above threshold\n",
    "    series_cols_remove = series_cols[series_cols.values >= NANthreshold]\n",
    "    series_cols_keep = series_cols[(series_cols.values < NANthreshold) & (series_cols.values > 0) ]\n",
    "    \n",
    "    #put the to-remove column names in a list\n",
    "    list_colstodrop = series_cols_remove.index.tolist()\n",
    "\n",
    "    #drop the columns\n",
    "    df = df.drop(labels = list_colstodrop, axis=1)\n",
    "\n",
    "    #print the results\n",
    "    print('Dropped {} of {} Columns - containing more than {} NANs\\n'.format(\n",
    "          series_cols_remove.shape[0],colcount,NANthreshold))\n",
    "    print(series_cols_remove)\n",
    "    \n",
    "    print('\\n{} Columns remain with NANs\\n'.format(series_cols_keep.shape[0]))\n",
    "    print(series_cols_keep)\n",
    "    print('\\nShape before: ' + str(X.shape))\n",
    "    print('Shape after: ' + str(df.shape))\n",
    "    print('\\n')    \n",
    "    return df\n",
    "\n",
    "\n",
    "def my_feature_selector(mytype,X,y=[],threshold=None,k=None):  \n",
    "    \n",
    "    #reduces # of features in given x dataset by one of 3 ways:\n",
    "    #1) selectkbest  2) rfecv (recursive feature elim)  3) variancethreshold\n",
    "\n",
    "    mytype = str.lower(mytype)\n",
    "    \n",
    "    #Retain original column names\n",
    "    orig_cols = X.columns\n",
    "    \n",
    "    #Evaluate type and instatiate object\n",
    "    if mytype == 'selectkbest':\n",
    "        if k == None:\n",
    "            print('Try Again: To run selectKBest you must pass a k for number of features to select')\n",
    "            return X  \n",
    "        if len(y) == 0:\n",
    "            print('Try Again: To run selectKBest you must pass a y vector reflecting outcomes')\n",
    "            return X             \n",
    "        \n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        df_new = selector.fit_transform(X,y)\n",
    "        keep_list = selector.get_support()\n",
    "        scores = [orig_cols, selector.pvalues_, keep_list]\n",
    "        score_type = 'PValue'\n",
    "        \n",
    "    if mytype == 'rfecv':\n",
    "        if len(y) == 0:\n",
    "            print('Try Again: To run rfecv you must pass a y vector reflecting outcomes')\n",
    "            return X \n",
    "       \n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, n_jobs=-1)\n",
    "        df_new = selector.fit_transform(X,y)\n",
    "        keep_list = selector.get_support()\n",
    "        scores = [orig_cols, selector.ranking_, keep_list]\n",
    "        score_type = 'Ranking'\n",
    "            \n",
    "    if mytype == 'variancethreshold':\n",
    "        if threshold == None:\n",
    "            print('Try Again: To run VarianceThreshold you must pass a threshold value from 0 to 1. (0 returns all)')\n",
    "            return X     \n",
    "    \n",
    "        selector = VarianceThreshold(threshold=threshold)\n",
    "        df_new = selector.fit_transform(X)\n",
    "        keep_list = selector.get_support()   \n",
    "        scores = [orig_cols, selector.variances_, keep_list]\n",
    "        score_type = 'Variance'\n",
    "        \n",
    "    if (mytype != 'selectkbest') & (mytype != 'rfecv') & (mytype != 'variancethreshold'):  \n",
    "        print('Try Again: Type must be passed as selectkbest, rfecv, or variancethreshold')\n",
    "        return X  \n",
    "    \n",
    "    \n",
    "    #Print Scores\n",
    "    print('---- Running Feature Selection Method: ' + mytype + '-------\\n')\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df = scores_df.transpose()\n",
    "    scores_df.columns= ['Feature',score_type,'Keep']\n",
    "    print(scores_df.sort_values(by=score_type, ascending=True))\n",
    "\n",
    "    #List features that were removed vs Kept\n",
    "    i = 0\n",
    "    keep = []\n",
    "\n",
    "    for item in keep_list:\n",
    "        col_name = orig_cols[i]\n",
    "        if item==True:\n",
    "            keep.append(col_name)\n",
    "        i = i + 1\n",
    "\n",
    "    #Place resultset of kept features into DataFrame with correct column headers\n",
    "    df_keep = pd.DataFrame(df_new, columns=keep)\n",
    "    \n",
    "    #Print Stats\n",
    "    print('\\nShape before: ' + str(X.shape))\n",
    "    print('Shape after: ' + str(df_keep.shape))\n",
    "    print('\\n')\n",
    "    return df_keep\n",
    "\n",
    "def my_confusion_matrix(array_Expected,array_Predicted,colName):\n",
    "    a = np.array(confusion_matrix(array_Expected, array_Predicted ))\n",
    "    totalExpectedFalse = a[0,0] + a[0,1]\n",
    "    totalExpectedTrue = a[1,0] + a[1,1]\n",
    "    correctFalse = a[0,0] \n",
    "    correctTrue = a[1,1] \n",
    "    correctTruePct = np.round(correctTrue / totalExpectedTrue,3)\n",
    "    correctFalsePct = np.round(correctFalse / totalExpectedFalse,3)\n",
    "    print('Regarding {}, the model correctly predicted {} Negatives out of {} expected Negatives: {}'.format(\n",
    "        colName,correctFalse,totalExpectedFalse,correctFalsePct))\n",
    "    print('Regarding {}, the model correctly predicted {} Positives out of {} expected Positives: {}'.format(\n",
    "        colName,correctTrue,totalExpectedTrue,correctTruePct))    \n",
    "    print(a)\n",
    "\n",
    "def my_minmax_scaler(df, min_val, max_val):\n",
    "    #Take in a dataframe and return a dataframe scaled with min 0, max 1\n",
    "    print('------Scaling Data to Min {}, Max {}------\\n'.format(min_val,max_val))\n",
    "    # Save the column names.\n",
    "    names=df.columns\n",
    "    \n",
    "    #instatiate scaler object\n",
    "    #you can use StandardScaler instead to scale with mean 0 and std 1\n",
    "    scaler = MinMaxScaler(feature_range=(min_val,max_val), copy=True)\n",
    "    \n",
    "    # Scale, then turn the resulting numpy array back into a data frame with the\n",
    "    # correct column names.\n",
    "    scaler.fit(df)\n",
    "    df_scaled = pd.DataFrame(scaler.transform(df), columns=names)\n",
    "    print('Scaling Complete')\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.23 s, sys: 138 ms, total: 2.37 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_data = pd.read_csv('creditcard.csv')\n",
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 31 vars removed due to corr greater than 0.8\n",
      "Empty DataFrame\n",
      "Columns: [var, variable, value]\n",
      "Index: []\n",
      "\n",
      "Shape before: (284807, 31)\n",
      "Shape after: (284807, 31)\n",
      "\n",
      "\n",
      "(284807,)\n",
      "(284807, 29)\n",
      "CPU times: user 457 ms, sys: 58.3 ms, total: 515 ms\n",
      "Wall time: 513 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = my_remove_highly_correlated(X=raw_data, threshold=.80)\n",
    "\n",
    "y = df.Class\n",
    "X = df.drop(columns=['Class','Time'], axis=1)\n",
    "\n",
    "\n",
    "#X = my_minmax_scaler(X, 0, 1)\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "#Split data into folds\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "skf = StratifiedShuffleSplit(n_splits=5, test_size=.2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "#X = my_feature_selector(mytype='selectkbest', X=X, y=Y, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- Random Forest --------------\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Strata # 1--------------\n",
      "Test Set Accuracy: 0.9995259997893332\n",
      "Regarding fraud, the model correctly predicted 56862 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 73 Positives out of 98 expected Positives: 0.745\n",
      "[[56862     2]\n",
      " [   25    73]]\n",
      "---------- Strata # 2--------------\n",
      "Test Set Accuracy: 0.999403110845827\n",
      "Regarding fraud, the model correctly predicted 56862 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 66 Positives out of 98 expected Positives: 0.673\n",
      "[[56862     2]\n",
      " [   32    66]]\n",
      "---------- Strata # 3--------------\n",
      "Test Set Accuracy: 0.9994908886626171\n",
      "Regarding fraud, the model correctly predicted 56860 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 73 Positives out of 98 expected Positives: 0.745\n",
      "[[56860     4]\n",
      " [   25    73]]\n",
      "---------- Strata # 4--------------\n",
      "Test Set Accuracy: 0.9994908886626171\n",
      "Regarding fraud, the model correctly predicted 56860 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 73 Positives out of 98 expected Positives: 0.745\n",
      "[[56860     4]\n",
      " [   25    73]]\n",
      "---------- Strata # 5--------------\n",
      "Test Set Accuracy: 0.9993504441557529\n",
      "Regarding fraud, the model correctly predicted 56861 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 64 Positives out of 98 expected Positives: 0.653\n",
      "[[56861     3]\n",
      " [   34    64]]\n",
      "CPU times: user 4min 47s, sys: 1.13 s, total: 4min 48s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=150, max_depth=10, max_features=2 )\n",
    "\n",
    "i = 1\n",
    "print ('---------------------------------------')\n",
    "print ('---------- Random Forest --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    print('Test Set Accuracy: ' + str(model.score(X_test, y_test)))\n",
    "    my_confusion_matrix(y_test, y_pred, 'fraud')\n",
    "    i = i + 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- K Nearest Neighbor --------------\n",
      "---------------------------------------\n",
      "---------- Strata # 1--------------\n",
      "Regarding fraud, the model correctly predicted 56856 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 55 Positives out of 98 expected Positives: 0.561\n",
      "[[56856     8]\n",
      " [   43    55]]\n",
      "---------- Strata # 2--------------\n",
      "Regarding fraud, the model correctly predicted 56861 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 56 Positives out of 98 expected Positives: 0.571\n",
      "[[56861     3]\n",
      " [   42    56]]\n",
      "---------- Strata # 3--------------\n",
      "Regarding fraud, the model correctly predicted 56858 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 59 Positives out of 98 expected Positives: 0.602\n",
      "[[56858     6]\n",
      " [   39    59]]\n",
      "---------- Strata # 4--------------\n",
      "Regarding fraud, the model correctly predicted 56861 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 51 Positives out of 98 expected Positives: 0.52\n",
      "[[56861     3]\n",
      " [   47    51]]\n",
      "---------- Strata # 5--------------\n",
      "Regarding fraud, the model correctly predicted 56856 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 58 Positives out of 98 expected Positives: 0.592\n",
      "[[56856     8]\n",
      " [   40    58]]\n",
      "CPU times: user 5min 30s, sys: 549 ms, total: 5min 31s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#'----------- K Nearest Neighbor --------------\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "i = 1\n",
    "print ('---------------------------------------')\n",
    "print ('---------- K Nearest Neighbor --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    my_confusion_matrix(y_test, y_pred, 'fraud')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- Logistic Regression --------------\n",
      "---------------------------------------\n",
      "---------- Strata # 1--------------\n",
      "Regarding fraud, the model correctly predicted 56852 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 61 Positives out of 98 expected Positives: 0.622\n",
      "[[56852    12]\n",
      " [   37    61]]\n",
      "---------- Strata # 2--------------\n",
      "Regarding fraud, the model correctly predicted 56847 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 73 Positives out of 98 expected Positives: 0.745\n",
      "[[56847    17]\n",
      " [   25    73]]\n",
      "---------- Strata # 3--------------\n",
      "Regarding fraud, the model correctly predicted 56849 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 69 Positives out of 98 expected Positives: 0.704\n",
      "[[56849    15]\n",
      " [   29    69]]\n",
      "---------- Strata # 4--------------\n",
      "Regarding fraud, the model correctly predicted 56858 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 65 Positives out of 98 expected Positives: 0.663\n",
      "[[56858     6]\n",
      " [   33    65]]\n",
      "---------- Strata # 5--------------\n",
      "Regarding fraud, the model correctly predicted 56858 Negatives out of 56864 expected Negatives: 1.0\n",
      "Regarding fraud, the model correctly predicted 58 Positives out of 98 expected Positives: 0.592\n",
      "[[56858     6]\n",
      " [   40    58]]\n",
      "CPU times: user 26.4 s, sys: 534 ms, total: 26.9 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#'----------- Logistic Regression --------------\n",
    "from sklearn import linear_model \n",
    "model = linear_model.LogisticRegression(penalty='l2', C=7000 )\n",
    "\n",
    "i = 1\n",
    "print ('---------------------------------------')\n",
    "print ('---------- Logistic Regression --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    my_confusion_matrix(y_test, y_pred, 'fraud')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
