{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 3000\n",
    "\n",
    "\n",
    "def my_remove_highly_correlated(X,threshold):\n",
    "\n",
    "    X = X.select_dtypes(include=[np.number])  #.dropna()\n",
    "    \n",
    "    cols = X.columns\n",
    "\n",
    "    #run correlation matrix\n",
    "    df = X.corr()\n",
    "   \n",
    "    #put df into array\n",
    "    a = df.values\n",
    "    \n",
    "    #label top half with -99999 \n",
    "    #we want to ignore top half of matrix\n",
    "    iu1 = np.triu_indices(len(df))\n",
    "    a[iu1] = -99999\n",
    "    #put data back into dataframe\n",
    "    df = pd.DataFrame(a, columns=cols)\n",
    "    df['var'] = cols\n",
    "    \n",
    "    #unstack to get a list of var1, var2, correlation\n",
    "    df = pd.melt(df, id_vars=['var'])\n",
    "        \n",
    "    #remove those flagged with -99999\n",
    "    df = df[df.value != -99999].sort_values(by='var', ascending=True)\n",
    "  \n",
    "    #flag remove vs keep based on corr threshold\n",
    "    df_remove = df[df.value > threshold]\n",
    "    remove_list = df_remove['var'].unique()\n",
    " \n",
    "    print('{} out of {} vars removed due to corr greater than {}'.\n",
    "          format(df_remove.shape[0],X.shape[1],threshold))\n",
    "    \n",
    "    new_df = X.drop(columns=remove_list, axis=1)\n",
    "    \n",
    "    print(df_remove)\n",
    "    print('\\nShape before: ' + str(X.shape))\n",
    "    print('Shape after: ' + str(new_df.shape))\n",
    "    print('\\n')\n",
    "    return new_df\n",
    "\n",
    "def my_drop_na_columns(X,NANthreshold):\n",
    "\n",
    "    df = X\n",
    "    colcount = df.shape[1]\n",
    "    #Get count of NA in each column\n",
    "    series_cols = df.isnull().sum(axis = 0).sort_values(ascending=False)\n",
    "\n",
    "    #filter the list to include only those with counts above threshold\n",
    "    series_cols_remove = series_cols[series_cols.values >= NANthreshold]\n",
    "    series_cols_keep = series_cols[(series_cols.values < NANthreshold) & (series_cols.values > 0) ]\n",
    "    \n",
    "    #put the to-remove column names in a list\n",
    "    list_colstodrop = series_cols_remove.index.tolist()\n",
    "\n",
    "    #drop the columns\n",
    "    df = df.drop(labels = list_colstodrop, axis=1)\n",
    "\n",
    "    #print the results\n",
    "    print('Flagged {} of {} Columns - containing more than {} NANs\\n'.format(\n",
    "          series_cols_remove.shape[0],colcount,NANthreshold))\n",
    "    print(series_cols_remove)\n",
    "    \n",
    "    print('\\n{} Columns remain with NANs\\n'.format(series_cols_keep.shape[0]))\n",
    "    print(series_cols_keep)\n",
    "    print('\\nShape before: ' + str(X.shape))\n",
    "    print('Shape after: ' + str(df.shape))\n",
    "    print('\\n')    \n",
    "    return df\n",
    "\n",
    "\n",
    "def my_confusion_matrix(array_Expected,array_Predicted,colName):\n",
    "    a = np.array(confusion_matrix(array_Expected, array_Predicted ))\n",
    "    totalExpectedFalse = a[0,0] + a[0,1]\n",
    "    totalExpectedTrue = a[1,0] + a[1,1]\n",
    "    correctFalse = a[0,0] \n",
    "    correctTrue = a[1,1] \n",
    "    correctTruePct = np.round(correctTrue / totalExpectedTrue,3)\n",
    "    correctFalsePct = np.round(correctFalse / totalExpectedFalse,3)\n",
    "    print('Regarding ' + colName + '...')\n",
    "    print('The model correctly predicted {} Negatives out of {} expected Negatives: {}'.format(\n",
    "        correctFalse,totalExpectedFalse,correctFalsePct))\n",
    "    print('The model correctly predicted {} Positives out of {} expected Positives: {}'.format(\n",
    "        correctTrue,totalExpectedTrue,correctTruePct))    \n",
    "    print(a)\n",
    "\n",
    "\n",
    "def my_show_feature_importance(feature_importances, X):\n",
    "\n",
    "    # Make importances relative to max importance.\n",
    "    feature_importances = 100.0 * (feature_importances / feature_importances.max())\n",
    "    \n",
    "    sorted_idx = np.argsort(feature_importances)\n",
    "    \n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importances[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 of 11 Columns - containing more than 100 NANs\n",
      "\n",
      "Series([], dtype: int64)\n",
      "\n",
      "0 Columns remain with NANs\n",
      "\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Shape before: (698, 11)\n",
      "Shape after: (698, 11)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class_Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0    1002945                5                        4   \n",
       "1    1015425                3                        1   \n",
       "2    1016277                6                        8   \n",
       "3    1017023                4                        1   \n",
       "4    1017122                8                       10   \n",
       "\n",
       "   Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                         4                  5                            7   \n",
       "1                         1                  1                            2   \n",
       "2                         8                  1                            3   \n",
       "3                         1                  3                            2   \n",
       "4                        10                  8                            7   \n",
       "\n",
       "  Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class_Malignant  \n",
       "0          10                3                2        1                0  \n",
       "1           2                3                1        1                0  \n",
       "2           4                3                7        1                0  \n",
       "3           1                3                1        1                0  \n",
       "4          10                9                7        1                1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_data.copy()\n",
    "\n",
    "#Name the columns\n",
    "col_names = [\n",
    "'id number',\n",
    "'Clump_Thickness',# 1 - 10 \n",
    "'Uniformity_of_Cell_Size',# 1 - 10 \n",
    "'Uniformity_of_Cell_Shape',# 1 - 10 \n",
    "'Marginal_Adhesion',# 1 - 10 \n",
    "'Single_Epithelial_Cell_Size',# 1 - 10 \n",
    "'Bare_Nuclei',# 1 - 10 \n",
    "'Bland_Chromatin',# 1 - 10 \n",
    "'Normal_Nucleoli',# 1 - 10 \n",
    "'Mitoses',# 1 - 10 \n",
    "'Class',# (2 for benign, 4 for malignant)\n",
    "]\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "#Binarize the Target variable\n",
    "df['Class_Malignant'] = np.where(df.Class == 4, 1, 0)\n",
    "df.drop(columns=['Class'], inplace=True)\n",
    "\n",
    "##Check for nulls\n",
    "df = my_drop_na_columns(df, 100)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id number</th>\n",
       "      <td>698.0</td>\n",
       "      <td>1.071807e+06</td>\n",
       "      <td>617532.274029</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>870258.25</td>\n",
       "      <td>1171710.0</td>\n",
       "      <td>1238354.0</td>\n",
       "      <td>13454352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <td>698.0</td>\n",
       "      <td>4.416905e+00</td>\n",
       "      <td>2.817673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <td>698.0</td>\n",
       "      <td>3.137536e+00</td>\n",
       "      <td>3.052575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <td>698.0</td>\n",
       "      <td>3.210602e+00</td>\n",
       "      <td>2.972867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <td>698.0</td>\n",
       "      <td>2.809456e+00</td>\n",
       "      <td>2.856606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <td>698.0</td>\n",
       "      <td>3.217765e+00</td>\n",
       "      <td>2.215408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <td>698.0</td>\n",
       "      <td>3.438395e+00</td>\n",
       "      <td>2.440056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <td>698.0</td>\n",
       "      <td>2.869628e+00</td>\n",
       "      <td>3.055004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>698.0</td>\n",
       "      <td>1.590258e+00</td>\n",
       "      <td>1.716162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_Malignant</th>\n",
       "      <td>698.0</td>\n",
       "      <td>3.452722e-01</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean            std      min  \\\n",
       "id number                    698.0  1.071807e+06  617532.274029  61634.0   \n",
       "Clump_Thickness              698.0  4.416905e+00       2.817673      1.0   \n",
       "Uniformity_of_Cell_Size      698.0  3.137536e+00       3.052575      1.0   \n",
       "Uniformity_of_Cell_Shape     698.0  3.210602e+00       2.972867      1.0   \n",
       "Marginal_Adhesion            698.0  2.809456e+00       2.856606      1.0   \n",
       "Single_Epithelial_Cell_Size  698.0  3.217765e+00       2.215408      1.0   \n",
       "Bland_Chromatin              698.0  3.438395e+00       2.440056      1.0   \n",
       "Normal_Nucleoli              698.0  2.869628e+00       3.055004      1.0   \n",
       "Mitoses                      698.0  1.590258e+00       1.716162      1.0   \n",
       "Class_Malignant              698.0  3.452722e-01       0.475798      0.0   \n",
       "\n",
       "                                   25%        50%        75%         max  \n",
       "id number                    870258.25  1171710.0  1238354.0  13454352.0  \n",
       "Clump_Thickness                   2.00        4.0        6.0        10.0  \n",
       "Uniformity_of_Cell_Size           1.00        1.0        5.0        10.0  \n",
       "Uniformity_of_Cell_Shape          1.00        1.0        5.0        10.0  \n",
       "Marginal_Adhesion                 1.00        1.0        4.0        10.0  \n",
       "Single_Epithelial_Cell_Size       2.00        2.0        4.0        10.0  \n",
       "Bland_Chromatin                   2.00        3.0        5.0        10.0  \n",
       "Normal_Nucleoli                   1.00        1.0        4.0        10.0  \n",
       "Mitoses                           1.00        1.0        1.0        10.0  \n",
       "Class_Malignant                   0.00        0.0        1.0         1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review Data\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 8 vars removed due to corr greater than 0.9\n",
      "                         var                 variable     value\n",
      "10  Uniformity_of_Cell_Shape  Uniformity_of_Cell_Size  0.906814\n",
      "\n",
      "Shape before: (698, 8)\n",
      "Shape after: (698, 7)\n",
      "\n",
      "\n",
      "(698,)\n",
      "(698, 7)\n",
      "CPU times: user 11.5 ms, sys: 1.31 ms, total: 12.8 ms\n",
      "Wall time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "#Split data into features X and target y\n",
    "y = df.Class_Malignant\n",
    "X = df.drop(columns=['Class_Malignant','id number'], axis=1)\n",
    "\n",
    "#Remove Highlight Correlated features\n",
    "X = my_remove_highly_correlated(X=X, threshold=.90)\n",
    "\n",
    "#X = my_minmax_scaler(X, 0, 1)\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data into folds for testing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "skf = StratifiedShuffleSplit(n_splits=5, test_size=.2)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.830831</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.175454</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.337860</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>0.089778</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461134</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.028898</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.978448</td>\n",
       "      <td>0.955587</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.745703</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.180551</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.955587</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.781769</td>\n",
       "      <td>0.033083</td>\n",
       "      <td>0.182909</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.429993</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.093130</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.359694</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>0.088536</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.952722</td>\n",
       "      <td>0.021785</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.470459</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>0.012206</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.861083</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>0.171083</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.459581</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.644301</td>\n",
       "      <td>0.144943</td>\n",
       "      <td>0.105942</td>\n",
       "      <td>0.019602</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.508816</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.945559</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491468</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.945559</td>\n",
       "      <td>0.029641</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.999903</td>\n",
       "      <td>0.100590</td>\n",
       "      <td>0.180892</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.944126</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.050074</td>\n",
       "      <td>0.238868</td>\n",
       "      <td>0.138627</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.944126</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.502285</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.092878</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.944126</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.839063</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.182573</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.944126</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.483157</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.941261</td>\n",
       "      <td>0.031642</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2        2.830831      0.048063         0.175454        0.005378   \n",
       "1        1.337860      0.013798         0.089778        0.004797   \n",
       "0        0.461134      0.007185         0.028898        0.000465   \n",
       "8        2.745703      0.058981         0.180551        0.003261   \n",
       "14       2.781769      0.033083         0.182909        0.002433   \n",
       "13       1.429993      0.020619         0.093130        0.001766   \n",
       "7        1.359694      0.011935         0.088536        0.001761   \n",
       "12       0.470459      0.009195         0.039518        0.012206   \n",
       "5        2.861083      0.023892         0.171083        0.001261   \n",
       "6        0.459581      0.008783         0.030459        0.000947   \n",
       "4        1.644301      0.144943         0.105942        0.019602   \n",
       "9        0.508816      0.022346         0.032313        0.001542   \n",
       "3        0.491468      0.035559         0.031746        0.001723   \n",
       "11       2.999903      0.100590         0.180892        0.009076   \n",
       "10       2.050074      0.238868         0.138627        0.022036   \n",
       "16       1.502285      0.095551         0.092878        0.003134   \n",
       "17       2.839063      0.025334         0.182573        0.011019   \n",
       "15       0.483157      0.012454         0.029755        0.001087   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  split0_test_score  \\\n",
       "2                5                  1               3000           0.935897   \n",
       "1                5                  1               1500           0.935897   \n",
       "0                5                  1                500           0.935897   \n",
       "8               10                  1               3000           0.935897   \n",
       "14              15                  1               3000           0.931624   \n",
       "13              15                  1               1500           0.931624   \n",
       "7               10                  1               1500           0.931624   \n",
       "12              15                  1                500           0.931624   \n",
       "5                5                  3               3000           0.918803   \n",
       "6               10                  1                500           0.931624   \n",
       "4                5                  3               1500           0.918803   \n",
       "9               10                  3                500           0.918803   \n",
       "3                5                  3                500           0.910256   \n",
       "11              10                  3               3000           0.914530   \n",
       "10              10                  3               1500           0.914530   \n",
       "16              15                  3               1500           0.914530   \n",
       "17              15                  3               3000           0.914530   \n",
       "15              15                  3                500           0.905983   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "2            0.952586           0.982759         0.957020        0.019398   \n",
       "1            0.952586           0.982759         0.957020        0.019398   \n",
       "0            0.952586           0.978448         0.955587        0.017512   \n",
       "8            0.948276           0.982759         0.955587        0.019827   \n",
       "14           0.948276           0.982759         0.954155        0.021298   \n",
       "13           0.948276           0.982759         0.954155        0.021298   \n",
       "7            0.943966           0.982759         0.952722        0.021785   \n",
       "12           0.939655           0.982759         0.951289        0.022445   \n",
       "5            0.952586           0.982759         0.951289        0.026144   \n",
       "6            0.939655           0.982759         0.951289        0.022445   \n",
       "4            0.948276           0.982759         0.949857        0.026152   \n",
       "9            0.935345           0.982759         0.945559        0.027104   \n",
       "3            0.943966           0.982759         0.945559        0.029641   \n",
       "11           0.935345           0.982759         0.944126        0.028554   \n",
       "10           0.935345           0.982759         0.944126        0.028554   \n",
       "16           0.935345           0.982759         0.944126        0.028554   \n",
       "17           0.935345           0.982759         0.944126        0.028554   \n",
       "15           0.935345           0.982759         0.941261        0.031642   \n",
       "\n",
       "    rank_test_score  \n",
       "2                 1  \n",
       "1                 1  \n",
       "0                 3  \n",
       "8                 3  \n",
       "14                5  \n",
       "13                5  \n",
       "7                 7  \n",
       "12                8  \n",
       "5                 8  \n",
       "6                 8  \n",
       "4                11  \n",
       "9                12  \n",
       "3                12  \n",
       "11               14  \n",
       "10               14  \n",
       "16               14  \n",
       "17               14  \n",
       "15               18  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------  GRID SEARCH:  RANDOM FOREST -------\n",
    "#-------------------------------------------\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=1000, max_depth=30, max_features=3 )\n",
    "\n",
    "#Random Forest Parameters\n",
    "n_estimators = [500,1500,3000]\n",
    "max_depth = [5,10,15]\n",
    "max_features = [1,3]\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "             'max_depth': max_depth,\n",
    "             'max_features': max_features}\n",
    "\n",
    "grid_search = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=3,\n",
    "                  return_train_score=False)\n",
    "grid_search.fit(X, y)\n",
    "grid_results_random_forest = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_results_random_forest.drop(columns=['params']).sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "grid_results_random_forest.drop(columns=['params']).sort_values(by='mean_test_score', ascending=False)\n",
    "#Best params =  max_depth=5, max_features=1, n_estimators=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- Random Forest --------------\n",
      "---------------------------------------\n",
      "---------- Strata # 1--------------\n",
      "Test Set Accuracy: 0.9785714285714285\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 92 Negatives out of 92 expected Negatives: 1.0\n",
      "The model correctly predicted 45 Positives out of 48 expected Positives: 0.938\n",
      "[[92  0]\n",
      " [ 3 45]]\n",
      "---------- Strata # 2--------------\n",
      "Test Set Accuracy: 0.9357142857142857\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 86 Negatives out of 92 expected Negatives: 0.935\n",
      "The model correctly predicted 45 Positives out of 48 expected Positives: 0.938\n",
      "[[86  6]\n",
      " [ 3 45]]\n",
      "---------- Strata # 3--------------\n",
      "Test Set Accuracy: 1.0\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 92 Negatives out of 92 expected Negatives: 1.0\n",
      "The model correctly predicted 48 Positives out of 48 expected Positives: 1.0\n",
      "[[92  0]\n",
      " [ 0 48]]\n",
      "---------- Strata # 4--------------\n",
      "Test Set Accuracy: 0.9571428571428572\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 87 Negatives out of 92 expected Negatives: 0.946\n",
      "The model correctly predicted 47 Positives out of 48 expected Positives: 0.979\n",
      "[[87  5]\n",
      " [ 1 47]]\n",
      "---------- Strata # 5--------------\n",
      "Test Set Accuracy: 0.9714285714285714\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 89 Negatives out of 92 expected Negatives: 0.967\n",
      "The model correctly predicted 47 Positives out of 48 expected Positives: 0.979\n",
      "[[89  3]\n",
      " [ 1 47]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 70.6 ms, total: 15.8 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#------  DISPLAY TYPE I and TYPE 2 RESULTS:  RANDOM FOREST -------\n",
    "#-----------------------------------------------------------------\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=3000, max_depth=5, max_features=1 )\n",
    "\n",
    "i = 1\n",
    "print ('---------------------------------------')\n",
    "print ('---------- Random Forest --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    print('Test Set Accuracy: ' + str(model.score(X_test, y_test)))\n",
    "    my_confusion_matrix(y_test, y_pred, 'Malignancy')\n",
    "    i = i + 1\n",
    "\n",
    "my_show_feature_importance(model.feature_importances_, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>40</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.952722</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.023219</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>40</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.948424</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.946991</td>\n",
       "      <td>0.031453</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.945559</td>\n",
       "      <td>0.031656</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       0.000964      0.000036         0.001362        0.000040   \n",
       "3       0.000909      0.000019         0.001640        0.000068   \n",
       "6       0.000922      0.000019         0.002149        0.000020   \n",
       "0       0.001183      0.000341         0.001528        0.000115   \n",
       "2       0.000941      0.000022         0.001688        0.000042   \n",
       "4       0.000897      0.000007         0.001901        0.000037   \n",
       "5       0.000919      0.000003         0.001862        0.000070   \n",
       "7       0.000940      0.000035         0.002116        0.000064   \n",
       "8       0.001128      0.000109         0.002913        0.000411   \n",
       "9       0.001276      0.000139         0.002953        0.000117   \n",
       "\n",
       "  param_n_neighbors param_weights  split0_test_score  split1_test_score  \\\n",
       "1                10       uniform           0.935897           0.943966   \n",
       "3                20       uniform           0.927350           0.952586   \n",
       "6                40      distance           0.923077           0.948276   \n",
       "0                10      distance           0.927350           0.943966   \n",
       "2                20      distance           0.923077           0.948276   \n",
       "4                30      distance           0.923077           0.948276   \n",
       "5                30       uniform           0.918803           0.948276   \n",
       "7                40       uniform           0.914530           0.943966   \n",
       "8                50      distance           0.910256           0.943966   \n",
       "9                50       uniform           0.910256           0.939655   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1           0.982759         0.954155        0.020450                1  \n",
       "3           0.982759         0.954155        0.022663                1  \n",
       "6           0.987069         0.952722        0.026331                3  \n",
       "0           0.982759         0.951289        0.023219                4  \n",
       "2           0.982759         0.951289        0.024475                4  \n",
       "4           0.982759         0.951289        0.024475                4  \n",
       "5           0.982759         0.949857        0.026152                7  \n",
       "7           0.987069         0.948424        0.029801                8  \n",
       "8           0.987069         0.946991        0.031453                9  \n",
       "9           0.987069         0.945559        0.031656               10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------  GRID SEARCH:  K NEAREST NEIGHBOR -------\n",
    "#-----------------------------------------------\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#KNN Parameters\n",
    "n_neighbors = [10,20,30,40,50]\n",
    "weights = ['distance','uniform']\n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors,\n",
    "             'weights': weights}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3,\n",
    "                  return_train_score=False)\n",
    "grid_search.fit(X, y)\n",
    "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "grid_results.drop(columns=['params']).sort_values(by='mean_test_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- K Nearest Neighbor --------------\n",
      "---------------------------------------\n",
      "---------- Strata # 1--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 90 Negatives out of 92 expected Negatives: 0.978\n",
      "The model correctly predicted 44 Positives out of 48 expected Positives: 0.917\n",
      "[[90  2]\n",
      " [ 4 44]]\n",
      "---------- Strata # 2--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 87 Negatives out of 92 expected Negatives: 0.946\n",
      "The model correctly predicted 46 Positives out of 48 expected Positives: 0.958\n",
      "[[87  5]\n",
      " [ 2 46]]\n",
      "---------- Strata # 3--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 88 Negatives out of 92 expected Negatives: 0.957\n",
      "The model correctly predicted 43 Positives out of 48 expected Positives: 0.896\n",
      "[[88  4]\n",
      " [ 5 43]]\n",
      "---------- Strata # 4--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 89 Negatives out of 92 expected Negatives: 0.967\n",
      "The model correctly predicted 45 Positives out of 48 expected Positives: 0.938\n",
      "[[89  3]\n",
      " [ 3 45]]\n",
      "---------- Strata # 5--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 87 Negatives out of 92 expected Negatives: 0.946\n",
      "The model correctly predicted 45 Positives out of 48 expected Positives: 0.938\n",
      "[[87  5]\n",
      " [ 3 45]]\n"
     ]
    }
   ],
   "source": [
    "#------  DISPLAY TYPE I and TYPE 2 RESULTS:  K NEAREST NEIGHBOR -------\n",
    "#-----------------------------------------------------------------\n",
    "i = 1\n",
    "model = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "print ('---------------------------------------')\n",
    "print ('---------- K Nearest Neighbor --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    my_confusion_matrix(y_test, y_pred, 'Malignancy')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>4.492277e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>5.550598e-06</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>3.339752e-06</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>7.786718e-07</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.752012e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.948424</td>\n",
       "      <td>0.025155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>1.215701e-06</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.948424</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1.189441e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.944126</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>1.036930e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>0.881089</td>\n",
       "      <td>0.051425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>4.730900e-03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.713675</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.766476</td>\n",
       "      <td>0.076580</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.072147e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.823276</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.690544</td>\n",
       "      <td>0.246029</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>4.203806e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "7        0.003411      0.000141         0.000269    4.492277e-05     100   \n",
       "8        0.001613      0.000095         0.000214    5.550598e-06    1000   \n",
       "9        0.002657      0.000666         0.000209    3.339752e-06    1000   \n",
       "10       0.001449      0.000064         0.000208    7.867412e-07   10000   \n",
       "11       0.002587      0.000664         0.000202    7.786718e-07   10000   \n",
       "5        0.002170      0.000122         0.000205    1.752012e-06       1   \n",
       "6        0.001430      0.000062         0.000203    1.215701e-06     100   \n",
       "4        0.001335      0.000021         0.000204    1.189441e-06       1   \n",
       "2        0.001210      0.000093         0.000211    1.036930e-05    0.01   \n",
       "0        0.015574      0.020397         0.003554    4.730900e-03   0.001   \n",
       "3        0.001185      0.000035         0.000205    1.072147e-06    0.01   \n",
       "1        0.000950      0.000027         0.000206    4.203806e-06   0.001   \n",
       "\n",
       "   param_penalty  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "7             l1           0.923077           0.943966           0.982759   \n",
       "8             l2           0.923077           0.943966           0.982759   \n",
       "9             l1           0.923077           0.943966           0.982759   \n",
       "10            l2           0.923077           0.943966           0.982759   \n",
       "11            l1           0.923077           0.943966           0.982759   \n",
       "5             l1           0.923077           0.939655           0.982759   \n",
       "6             l2           0.918803           0.943966           0.982759   \n",
       "4             l2           0.901709           0.948276           0.982759   \n",
       "2             l2           0.833333           0.857759           0.952586   \n",
       "0             l2           0.713675           0.711207           0.875000   \n",
       "3             l1           0.901709           0.823276           0.344828   \n",
       "1             l1           0.653846           0.655172           0.655172   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "7          0.949857        0.024734                1  \n",
       "8          0.949857        0.024734                1  \n",
       "9          0.949857        0.024734                1  \n",
       "10         0.949857        0.024734                1  \n",
       "11         0.949857        0.024734                1  \n",
       "5          0.948424        0.025155                6  \n",
       "6          0.948424        0.026317                6  \n",
       "4          0.944126        0.033241                8  \n",
       "2          0.881089        0.051425                9  \n",
       "0          0.766476        0.076580               10  \n",
       "3          0.690544        0.246029               11  \n",
       "1          0.654728        0.000626               12  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------  GRID SEARCH:  LOGISTIC REGRESSION -------\n",
    "#-----------------------------------------------\n",
    "from sklearn import linear_model \n",
    "\n",
    "#KNN Parameters\n",
    "penalty = ['l2','l1']\n",
    "C = [.001,.01,1,100,1000,10000]\n",
    "\n",
    "\n",
    "param_grid = {'penalty': penalty,\n",
    "             'C': C}\n",
    "\n",
    "grid_search = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=3,\n",
    "                  return_train_score=False)\n",
    "grid_search.fit(X, y)\n",
    "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "grid_results.drop(columns=['params']).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "---------- Logistic Regression --------------\n",
      "---------------------------------------\n",
      "---------- Strata # 1--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 88 Negatives out of 92 expected Negatives: 0.957\n",
      "The model correctly predicted 47 Positives out of 48 expected Positives: 0.979\n",
      "[[88  4]\n",
      " [ 1 47]]\n",
      "---------- Strata # 2--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 90 Negatives out of 92 expected Negatives: 0.978\n",
      "The model correctly predicted 44 Positives out of 48 expected Positives: 0.917\n",
      "[[90  2]\n",
      " [ 4 44]]\n",
      "---------- Strata # 3--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 89 Negatives out of 92 expected Negatives: 0.967\n",
      "The model correctly predicted 46 Positives out of 48 expected Positives: 0.958\n",
      "[[89  3]\n",
      " [ 2 46]]\n",
      "---------- Strata # 4--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 91 Negatives out of 92 expected Negatives: 0.989\n",
      "The model correctly predicted 47 Positives out of 48 expected Positives: 0.979\n",
      "[[91  1]\n",
      " [ 1 47]]\n",
      "---------- Strata # 5--------------\n",
      "Regarding Malignancy...\n",
      "The model correctly predicted 90 Negatives out of 92 expected Negatives: 0.978\n",
      "The model correctly predicted 45 Positives out of 48 expected Positives: 0.938\n",
      "[[90  2]\n",
      " [ 3 45]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 429 ms, sys: 58.9 ms, total: 488 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#------  DISPLAY TYPE I and TYPE 2 RESULTS:  LOGISTIC REGRESSION -------\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l1', C=100 )\n",
    "\n",
    "i = 1\n",
    "print ('---------------------------------------')\n",
    "print ('---------- Logistic Regression --------------')\n",
    "print ('---------------------------------------')\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('---------- Strata # ' + str(i) + '--------------')\n",
    "    my_confusion_matrix(y_test, y_pred, 'Malignancy')\n",
    "    coef = np.abs(model.coef_)\n",
    "    coef = coef.reshape(coef.shape[1],)\n",
    "    i = i + 1\n",
    "    \n",
    "my_show_feature_importance(coef,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
